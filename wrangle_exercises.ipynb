{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c08334a",
   "metadata": {},
   "source": [
    "# Wrangle Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d1dcea",
   "metadata": {},
   "source": [
    "### Data Acquisition\n",
    "- These exercises should go in a notebook or script named wrangle. Add, commit, and push your changes.\n",
    "- This exercises uses the case.csv, dept.csv, and source.csv files from the san antonio 311 call dataset.\n",
    "\n",
    "1. Read the case, department, and source data into their own spark dataframes.\n",
    "\n",
    "2.  Let's see how writing to the local disk works in spark:\n",
    "\n",
    "- Write the code necessary to store the source data in both csv and json format, store these as sources_csv and sources_json\n",
    "\n",
    "- Inspect your folder structure. What do you notice?\n",
    "\n",
    "3. Inspect the data in your dataframes. \n",
    "- Are the data types appropriate? \n",
    "- Write the code necessary to cast the values to the appropriate types.\n",
    "\n",
    "-----------\n",
    "\n",
    "1. How old is the latest (in terms of days past SLA) currently open issue? How long has the oldest (in terms of days since opened) currently opened issue been open?\n",
    "\n",
    "2. How many Stray Animal cases are there?\n",
    "\n",
    "3. How many service requests that are assigned to the Field Operations department (dept_division) are not classified as \"Officer Standby\" request type (service_request_type)?\n",
    "\n",
    "4. Convert the council_district column to a string column.\n",
    "\n",
    "5. Extract the year from the case_closed_date column.\n",
    "\n",
    "6. Convert num_days_late from days to hours in new columns num_hours_late.\n",
    "\n",
    "7. Join the case data with the source and department data.\n",
    "\n",
    "8. Are there any cases that do not have a request source?\n",
    "\n",
    "9. What are the top 10 service request types in terms of number of requests?\n",
    "\n",
    "10. What are the top 10 service request types in terms of average days late?\n",
    "\n",
    "11. Does number of days late depend on department?\n",
    "\n",
    "12. How do number of days late depend on department and request type?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f095a5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "939c02e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in CSV file \n",
    "source = (spark.read.csv(\"source.csv\",\n",
    "                     sep=\",\",\n",
    "                     header=True,\n",
    "                     inferSchema=True)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17aeb224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another way to read in data:\n",
    "\n",
    "# (\n",
    "#     spark.read.format(\"csv\")\n",
    "#     .option(\"sep\", \",\")\n",
    "#     .option(\"inferSchema\", True)\n",
    "#     .option(\"header\", True)\n",
    "#     .load(\"source.csv\")\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ba3ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.sql.types import StructType, StructField, StringType\n",
    "\n",
    "# schema = StructType(\n",
    "#     [\n",
    "#         StructField(\"source_id\", StringType()),\n",
    "#         StructField(\"source_username\", StringType()),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "\n",
    "# # Read csv, but now we specify the schema:\n",
    "\n",
    "# source = spark.read.csv(\"source.csv\", header=True, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ff844b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in CSV file \n",
    "case = (spark.read.csv(\"case.csv\",\n",
    "                     sep=\",\",\n",
    "                     header=True,\n",
    "                     inferSchema=True)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f4eacb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in CSV file \n",
    "dept = (spark.read.csv(\"dept.csv\",\n",
    "                     sep=\",\",\n",
    "                     header=True,\n",
    "                     inferSchema=True)\n",
    "     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446177f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "source.write.json('source_json', mode='overwrite')\n",
    "source.write.json('case_json', mode='overwrite')\n",
    "source.write.json('dept_json', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2715cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- source_id: string (nullable = true)\n",
      " |-- source_username: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "source.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ce970fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 140)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of dataframe\n",
    "len(source.columns), source.count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d4e8994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 841704)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of dataframe\n",
    "len(case.columns), case.count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "024744c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 39)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shape of dataframe\n",
    "len(dept.columns), dept.count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7e0077",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
